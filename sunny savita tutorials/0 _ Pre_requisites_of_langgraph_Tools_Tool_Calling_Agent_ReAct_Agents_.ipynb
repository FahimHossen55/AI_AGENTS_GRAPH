{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "-  LangChain AI agents\n",
        "- Tools\n",
        "- Tool calling Agent\n",
        "-  ReAct Agents\n"
      ],
      "metadata": {
        "id": "-u8GxRT6NXIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predefine Tools :**"
      ],
      "metadata": {
        "id": "IAxuvJH6PqNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h6V3Uz4Mx_7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community  langchain  wikipedia\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "api_wrapper = WikipediaAPIWrapper()\n",
        "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "print(tool.run({\"query\" : \"langchain\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u86ghcRQxXC",
        "outputId": "501da930-94d6-40c9-cf03-cb28a61d0b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
            "\n",
            "Page: Retrieval-augmented generation\n",
            "Summary: Retrieval augmented generation (RAG) is a type of generative artificial intelligence that has information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information in preference to information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
            "Use cases include providing chatbot access to internal company data, or giving factual information only from an authoritative source.\n",
            "\n",
            "Page: DataStax\n",
            "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_search"
      ],
      "metadata": {
        "id": "izNa6LTlScIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import YouTubeSearchTool\n",
        "tool2 = YouTubeSearchTool()\n",
        "\n",
        "print(tool2.run(\" july protest in bangladesh \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fptpU3jiRXdw",
        "outputId": "f83b19e2-7c91-4986-83f2-1d95937d4736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.youtube.com/watch?v=6WEIgVL_KqI&pp=ygUcIGp1bHkgcHJvdGVzdCBpbiBiYW5nbGFkZXNoIA%3D%3D', 'https://www.youtube.com/watch?v=LqCkSrJeieU&pp=ygUcIGp1bHkgcHJvdGVzdCBpbiBiYW5nbGFkZXNoIA%3D%3D']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('tavily_api_key')\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tool =  TavilySearchResults()\n",
        "tool.invoke({\"query\" : \"who is the founder of open ai ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f4MBkiqSWDK",
        "outputId": "d78ddb80-bb46-4351-f7c4-0a514eaca190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/',\n",
              "  'content': 'The inside story of ChatGPT: How OpenAI founder Sam Altman built the world’s hottest technology with billions from Microsoft\\nA few times in a generation, a product comes along that catapults a technology from the fluorescent gloom of engineering department basements, the fetid teenage bedrooms of nerds, and the lonely man caves of hobbyists—into something that your great-aunt Edna knows how to use. The amount of safety work we are doing keeps increasing.”\\n“The amount of safety work we are doing keeps increasing.”\\nCritics, however, say OpenAI’s product-oriented approach to advanced A.I. is irresponsible, the equivalent of giving people loaded guns on the grounds that it is the best way to determine if they will actually shoot one another.\\n According to documents seen by Fortune, on completion of its new investment and after OpenAI’s first investors earn back their initial capital, Microsoft will be entitled to 75% of OpenAI’s profits until it earns back the $13\\xa0billion it has invested—a figure that includes an earlier $2\\xa0billion investment in OpenAI that had not been previously disclosed until Fortune reported it in January. , McCauley is a supporter of Effective Altruism, the philosophical movement that has as one of its preoccupations the dangers of superintelligent A.I.\\nAdam D’AngeloAn early Facebook executive—he was chief technology officer during some of its boom years in the late 2000s—D’Angelo went on to cofound the online question-answering service Quora.\\n He left the board in 2018, saying at one point that he faced conflicts of interest as Tesla began developing its own advanced A.I.\\nVenture capital muscle\\nIn 2021, OpenAI sold existing shares of the business in a tender\\xa0offer that valued the startup at about $14\\xa0billion—and brought three heavy-hitting VC firms into its orbit.'},\n",
              " {'url': 'https://en.wikipedia.org/wiki/Greg_Brockman',\n",
              "  'content': 'He left Stripe in 2015[5] to co-found OpenAI, where he also assumed the role of CTO.[6][7][8][9]\\nEarly life and education[edit]\\nBrockman was born in Thompson, North Dakota, and attended Red River High School, where he excelled in mathematics, chemistry, and computer science.[6][10] He won a silver medal in the 2006 International Chemistry Olympiad[11] and became the first finalist from North Dakota to participate in the Intel science talent search since 1973.[12] Brockman left Stripe in May 2015, and co-founded OpenAI[16] in December 2015 with Sam Altman and Ilya Sutskever.[15][17]\\nBrockman helped create the OpenAI founding team, and led various prominent projects early on at OpenAI, including OpenAI Gym and OpenAI Five, a Dota 2 bot.[18][19][8][20]\\nOn February 14, 2019, OpenAI announced that they had developed a new large language model called GPT-2,[21] but kept it private due to their concern for its potential misuse. They finally released the model to a limited group of beta testers in May 2019.[6][22]\\nOn March 14, 2023, in a live video demo, Brockman unveiled GPT-4,[23][24] the fourth iteration in the GPT series, and the newest language model created by OpenAI.[7][25][26][27]\\n On November 17, 2023, along with the firing of Sam Altman from OpenAI, Greg Brockman was told he was being removed from the board, but was vital to the company and would remain in his role at the company, reporting to the CEO.[28][29] He later in the day announced on X (formerly known as Twitter) he had quit the company.[30]\\nOn November 20, 2023, Microsoft CEO Satya Nadella announced that Brockman and former OpenAI CEO Sam Altman would join Microsoft to lead a new advanced AI research team.[31]'},\n",
              " {'url': 'https://www.entrepreneur.com/business-news/who-is-openai-ceo-sam-altman-net-worth-education/463514',\n",
              "  'content': 'In a few short years, Sam Altman has become one of the most influential names in the artificial intelligence movement. The 38-year-old is the CEO of OpenAI, the artificial intelligence lab that ...'},\n",
              " {'url': 'https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/',\n",
              "  'content': 'It should not assume an identity that it doesn’t have, it shouldn’t claim to have abilities that it doesn’t possess, and when a user asks it to do tasks that it’s not supposed to do, it has to write a refusal message. In addition to Agarwal and Fedus, I spoke to John Schulman, a cofounder of OpenAI, and Jan Leike, the leader of OpenAI’s alignment team, which works on the problem of making AI do what its users want it to do (and nothing more).\\n What I came away with was the sense that OpenAI is still bemused by the success of its research preview, but has grabbed the opportunity to push this technology forward, watching how millions of people are using it and trying to fix the worst problems as they come up.\\n The team has tried to jump on the most problematic examples of what ChatGPT can produce—from songs about God’s love for rapist priests to malware code that steals credit card numbers—and use them to rein in future versions of the model.\\n To get the inside story behind the chatbot—how it was made, how OpenAI has been updating it since release, and how its makers feel about its success—I talked to four people who helped build what has become one of the most popular internet apps ever.'},\n",
              " {'url': 'https://en.wikipedia.org/wiki/OpenAI',\n",
              "  'content': 'The board initially contacted Anthropic CEO Dario Amodei who was a former executive at OpenAI to replace Altman and proposed a merger, both offers were declined.[73]\\nOn November 20, 2023, Microsoft CEO Satya Nadella announced Altman and Brockman will be joining the company to lead a new research team regarding advanced AI, and state they are still committed to OpenAI despite the turn of events.[74] The partnership had not been finalized as Altman gave the board another opportunity to negotiate with him.[75] About 738 of OpenAI\\'s 770 employees, including Murati and Sutskever, signed an open letter stating they would quit their jobs and join Microsoft if the board does not re-hire Altman as CEO and then resign.[76][77] Investors are considering taking legal action against the board members in response to potential mass resignations and Altman\\'s removal.[78] OpenAI cautioned that such scaling up of language models could be approaching or encountering the fundamental capability limitations of predictive language models.[148] Pre-training GPT-3 required several thousand petaflop/s-days[b] of compute, compared to tens of petaflop/s-days for the full GPT-2 model.[145] Like its predecessor,[134] the GPT-3 trained model was not immediately released to the public on the grounds of possible abuse, although OpenAI planned to allow access through a paid cloud API after a two-month free private beta that began in June 2020.[130][150]\\nOn September 23, 2020, GPT-3 was licensed exclusively to Microsoft.[151][152]\\nAnnounced in mid-2021, Codex is a descendant of GPT-3 that has additionally been trained on code from 54 million GitHub repositories,[153][154] and is the AI powering the code autocompletion tool GitHub Copilot.[154] At The International 2018, OpenAI Five played in two exhibition matches against professional players, but ended up losing both games.[117][118][119] In April 2019, OpenAI Five defeated OG, the reigning world champions of the game at the time, 2:0 in a live exhibition match in San Francisco.[120][121] The bots\\' final public appearance came later that month, where they played in 42,729 total games in a four-day open online competition, winning 99.4% of those games.[122]\\nOpenAI Five\\'s mechanisms in Dota 2\\'s bot player shows the challenges of AI systems in multiplayer online battle arena (MOBA) games and how OpenAI Five has demonstrated the use of deep reinforcement learning (DRL) agents to achieve superhuman competence in Dota 2 matches.[123]\\nReleased in 2018, Gym Retro is a platform for reinforcement learning (RL) research on video games.[124] In 2016, OpenAI paid corporate-level (rather than nonprofit-level) salaries, but did not pay AI researchers salaries comparable to those of Facebook or Google.[21]\\nMicrosoft\\'s Peter Lee stated that the cost of a top AI researcher exceeds the cost of a top NFL quarterback prospect.[21] OpenAI\\'s potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of the very strong group of people and, to a very large extent, because of its mission. \"[18] Co-chair Sam Altman expects the decades-long project to surpass human intelligence.[93]\\nVishal Sikka, the former CEO of Infosys, stated that an \"openness\" where the endeavor would \"produce results generally in the greater interest of humanity\" was a fundamental requirement for his support, and that OpenAI \"aligns very nicely with our long-held values\" and their \"endeavor to do purposeful work\".[94] Cade Metz of Wired suggests that corporations such as Amazon may be motivated by a desire to use open-source software and data to level the playing field against corporations such as Google and Facebook which own enormous supplies of proprietary data.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Custom tools :**"
      ],
      "metadata": {
        "id": "iGcG5TuNT1EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_word_lenth(word ) :\n",
        "  \"\"\"This tool calculates the length of a word.\n",
        "\n",
        "  Args:\n",
        "    word: The word to calculate the length of.\n",
        "\n",
        "  Returns:\n",
        "    The length of the word.\n",
        "  \"\"\"\n",
        "  return len(word)\n",
        "\n",
        "# Example usage\n",
        "get_word_lenth.invoke(\"i am fahim\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHXFD-eDTJjW",
        "outputId": "7dd9f4e8-a19b-4ab2-9922-0ccee30fa132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_lenth.run(\"abc124\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x0XuG7iURVw",
        "outputId": "4ca112a6-36bc-4c62-c0d3-a669270e663e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(a : int , b : int) -> int :\n",
        "  \"\"\" Multify two numbers together \"\"\"\n",
        "  return a * b"
      ],
      "metadata": {
        "id": "UMqEnnkOVrdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3jcO1xqNV0W7",
        "outputId": "fe263bf9-72b8-4c16-e789-07c5c1086c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'multiply'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KlujeEhHV51k",
        "outputId": "0ed5fe21-a709-4aba-c5dd-cab8ba041d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Multify two numbers together'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7CKLmH-V82A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiply({\"a\" : 10 , \"b\" : 12})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLcH9DI6WBDo",
        "outputId": "76d4e2a2-d96b-41f4-df4c-8fe7045b8f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Concept Of Agents :**\n",
        "#### This Agent class from the first version of  langchain"
      ],
      "metadata": {
        "id": "VV7Ynlo6W282"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ],
      "metadata": {
        "id": "Sky0NO3mWOK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "# Set the Hugging Face API key\n",
        "os.environ['HUGGINGFACE_API_KEY'] = userdata.get('hugginface_key')\n",
        "\n",
        "# Initialize the Hugging Face Hub LLM\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64},\n",
        "    huggingfacehub_api_token=userdata.get('hugginface_key')\n",
        ")\n",
        "\n",
        "# Correct usage of load_tools\n",
        "tools = load_tools([\"wikipedia\"], llm=llm)"
      ],
      "metadata": {
        "id": "23yvPDV_XWWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcLE4uCTaVq4",
        "outputId": "fa20d03d-dc1a-49cd-fe7d-70d8758c54ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools[0].invoke({\"query\" : \"langchain\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "tFNqcd66Y-o0",
        "outputId": "214d9634-c4e3-425b-8933-c7048d3eace3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval augmented generation (RAG) is a type of generative artificial intelligence that has information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information in preference to information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \\nUse cases include providing chatbot access to internal company data, or giving factual information only from an authoritative source.\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools ,  llm ,agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION )"
      ],
      "metadata": {
        "id": "I-nu10fsaO2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"what is the capital of bangladesh ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7d8XK0bQc2Jr",
        "outputId": "3ca8e574-09a4-4249-fe4d-6789b860a295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Agent stopped due to iteration limit or time limit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"hello , how are you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5y3PF6oMc5HO",
        "outputId": "e4085c9f-d762-4c8a-e016-2e44c669fa66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Agent stopped due to iteration limit or time limit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zWN4jSYSdVVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}