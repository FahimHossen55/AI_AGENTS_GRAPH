{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Langgraph**"
      ],
      "metadata": {
        "id": "uB68-etM_6v2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What is Langgraph ?**\n",
        "\n",
        "**Ans :** Langgraph is a library or building statefull ,multi-actor applications with LLms , used to create agent and multi-agent workflows. Compareed to other LLM framworks , it offers these core benefits :cycles , controllability , and persistance. Langgraphh allows you to define  flows that involve cycles , essential for most agentic architectures , differtianting it from DAG-based solutions."
      ],
      "metadata": {
        "id": "79tLdkvTAFn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Langgraph  :**\n",
        "1.  Amazing Benefits\n",
        "2. Simplifies developments\n",
        "3. **Flexibility :**\n",
        "\n",
        "\n",
        " With Langgraph , developers have the flexibility to define their own agent logic and communication protocols. this allows for higher customized applications tailored to specific use cases.Whether you need a chatbot that can handle various types of user request or a multi-agent system that performs that performs complex tasks , Langgraph provides the tools to build exactly what you need. its all about giving you the power to create.\n",
        "\n",
        " 4. Scalability :  building the multi-agent application we can actually build\n",
        " 5. Fault Tolerance"
      ],
      "metadata": {
        "id": "pelBRte2CMnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langsmith"
      ],
      "metadata": {
        "id": "apRaOkDSDp8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq langchain_community"
      ],
      "metadata": {
        "id": "oIAPZHpZGP1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "YIWEIX_Wez2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "groq_apikey =  userdata.get('groq_api')"
      ],
      "metadata": {
        "id": "FTqDXayXcnlu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langsmith =  userdata.get('langsmith')"
      ],
      "metadata": {
        "id": "o3Uzlpuqg8k9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LANGCHAIN_TRACING_V2=True\n",
        "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
        "LANGCHAIN_API_KEY=langsmith\n",
        "LANGCHAIN_PROJECT=\"learning-8-9-24\""
      ],
      "metadata": {
        "id": "WfEOtPcwj3z2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "_NZNyuG8lNko"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llms  =  ChatGroq(groq_api_key =groq_apikey, model_name = \"Gemma2-9b-It\")"
      ],
      "metadata": {
        "id": "QSi1_QNOmkT7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llms.invoke(\"hello , who are you ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtSsH9m1m5jD",
        "outputId": "6f6c9377-1e70-4e91-eaaf-ca901c02c7dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello! I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\\n\\nIs there anything else you'd like to know about me?\\n\", response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 15, 'total_tokens': 57, 'completion_time': 0.076363636, 'prompt_time': 0.00012061, 'queue_time': 0.01407752, 'total_time': 0.076484246}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a33783e6-dd2f-4ec9-99c9-1f61cb58f361-0', usage_metadata={'input_tokens': 15, 'output_tokens': 42, 'total_tokens': 57})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Start Building Chatbot using Langgraph**"
      ],
      "metadata": {
        "id": "DHF-cyNUnN1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict"
      ],
      "metadata": {
        "id": "njaoaSRlouft"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph , START , END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "ETOoFBrRnHI4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Example function for metadata (this is hypothetical unless defined elsewhere)\n",
        "\n",
        "# Correcting the structure\n",
        "class State(TypedDict):\n",
        "    # The first argument is the type 'list', and you can add metadata if needed.\n",
        "    messages: Annotated[List[str], add_messages]  # Use List[str] to specify the type of items inside the list\n",
        "\n"
      ],
      "metadata": {
        "id": "o-PeFkavm_9i"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "       messages: List[str]\n",
        "graph = StateGraph(State)"
      ],
      "metadata": {
        "id": "bkLPeI9dpYVz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ba_DWAyrYOp",
        "outputId": "db25bd57-d873-4c80-e8a3-6ec155a69e9b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cca34a7e260>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State) :\n",
        "  return {\"messages\" : llm.invoke(state[\"messages\"])}"
      ],
      "metadata": {
        "id": "3IiWOdiAy7q2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSal-VFJzOJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}