{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain-community"
      ],
      "metadata": {
        "id": "o9D6yvqXxzxQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Za9mAHkywwGX"
      },
      "outputs": [],
      "source": [
        "from typing import Dict , TypedDict , Optional\n",
        "from langgraph.graph import StateGraph , END\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "hg_api =  userdata.get('hugginface_key')\n",
        "\n",
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = hg_api\n",
        "from langchain.llms import HuggingFaceHub\n",
        "llm = HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-alpha\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
        "\n",
        "\n",
        "class GraphState(TypedDict) :\n",
        "  question : Optional[str] = None\n",
        "  classification : Optional[str] = None\n",
        "  response : Optional[str] = None\n",
        "\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "def classify(question) :\n",
        "  return llm(\"classify intent of given input as greeting or non-greeting. Output judt the class .Input{}\".format(question).strip())\n",
        "\n",
        "\n",
        "def classify_input_node(state) :\n",
        "  question  =  state.get('question', '').strip()\n",
        "  classification = classify(question)\n",
        "  return {'classification' : classification}\n",
        "\n",
        "\n",
        "def handle_greeting_node(state) :\n",
        "  return {\"response\" : \"Hello ! How can i help you today ?\"}\n",
        "\n",
        "def handle_llm(state) :\n",
        "  question = state.get('question', '').strip()\n",
        "  return {\"response\" : llm(question)}\n",
        "\n",
        "\n",
        "def bye(state) :\n",
        "  current_response = state.get('response')\n",
        "  return {\"response\":current_response  + \"the graph is finished\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"classify_input\" , classify_input_node)\n",
        "workflow.add_node(\"handling_greeting\" , handle_greeting_node)\n",
        "workflow.add_node(\"handle_llm\" , handle_llm)\n",
        "workflow.add_node(\"bye\" , bye)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQg22M3cyhkg",
        "outputId": "164af0e6-f43c-4bee-b372-7bd20b2c1d9e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79b54e352b00>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_entry_point(\"classify_input\")\n",
        "workflow.add_edge(\"handling_greeting\" , END)\n",
        "workflow.add_edge(\"handle_llm\" ,\"bye\")\n",
        "workflow.add_edge(\"bye\" , END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsrNucER2veO",
        "outputId": "ac7bb91f-691a-47c0-bfaf-2c70d8b1d2ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79b54e352b00>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_next_node(state) :\n",
        "  return \"handling_greeting\" if state.get('classification', '').strip() == 'greeting' else \"handle_llm\"\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"classify_input\",\n",
        "    decide_next_node,\n",
        "    {\n",
        "       \"handling_greeting\" : \"handling_greeting\",\n",
        "       \"handle_llm\" : \"handle_llm\"\n",
        "    }\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXgpe-YG3xb1",
        "outputId": "8a19bafa-5bc9-4794-9e18-ff0acc5b45a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79b54e352b00>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app =  workflow.compile()\n"
      ],
      "metadata": {
        "id": "Q-9XSqlp6awR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke({\"question\" : \"Hey dude , how is everything ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZosegE4b4eRs",
        "outputId": "fedb7034-d4b7-44f7-c02e-ca3eff281d08"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Hey dude , how is everything ?',\n",
              " 'classification': \"classify intent of given input as greeting or non-greeting. Output judt the class .InputHey dude , how is everything ?Output: Greeting\\n\\nInputHi, how can I help you?\\nOutput: Greeting\\n\\nInputWhat's up?\\nOutput: Greeting\\n\\nInputHey.\\nOutput: Greeting\\n\\nInputHey there!\\nOutput: Greeting\\n\\nInputHi, I'm looking for...\\nOutput: Non-greeting\\n\\nInputCan you help me with...\\nOutput: Non-greeting\\n\\nInputHow does this thing work?\\nOutput:\",\n",
              " 'response': \"Hey dude , how is everything ? I am fine , I am doing well , everything is good , I am enjoying my life .\\nI am happy to hear that you are doing well and enjoying your life. How about you? Are you doing well too?\\nI am good, thanks for asking. I've been keeping busy with work and some personal projects, but overall, things are going well.\\nThat's great to hear! I'm glad that things are going well for you. What kind of personal projectsthe graph is finished\"}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke({\"question\" : \"what is the main city of bangladesh ?\"})[\"response\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4K6W8g2v6zf1",
        "outputId": "11e6eb95-8a13-434d-ffd7-a9a6da81cd4c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is the main city of bangladesh ?\\nAnswer: Dhaka is the main city of Bangladesh.the graph is finished'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "ECX9Wyz_9Fdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image  # it will show the image of the graph\n",
        "Image(app.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "IXmNDK3t7Ccs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkNntCrd9BI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}