{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9DN02-g1SUa",
        "outputId": "6c1d8dea-f893-47ea-d7e2-4ebb2359986e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed dataclasses-json-0.6.7 groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-core-0.2.38 langchain-text-splitters-0.2.4 langchain_community-0.2.16 langchain_groq-0.1.9 langsmith-0.1.116 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 tenacity-8.5.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community langsmith langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict"
      ],
      "metadata": {
        "id": "1YK2aOeG1iNg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "uhbyuq-74K8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Working with  tools\n",
        "\n",
        "\n",
        "\n",
        "from langchain_community.utilities import ArxivAPIWrapper , WikipediaAPIWrapper\n",
        "from langchain_community.tools import ArxivQueryRun , WikipediaQueryRun\n",
        "\n",
        "## Arxiv and Wikipedia tools\n",
        "\n",
        "arxiv_wrapper =  ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=300)\n",
        "arxiv_tool = ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n"
      ],
      "metadata": {
        "id": "vb25Fdze20MB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsC1mjbV4cyb",
        "outputId": "287b07db-eff5-489c-c9b1-3ba5d90f26e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ArxivQueryRun()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max =300)\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper) # The parameter name has been corrected."
      ],
      "metadata": {
        "id": "QIcWq6Lo4dHH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJteLunH4f7A",
        "outputId": "03b89e31-b986-4e23-fa52-aa8d708478d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=300))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool.invoke(\"Who is the current president of the United States?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "XSyxagfl5jr2",
        "outputId": "b5af4f7e-2d40-4cfd-ad69-c4e15db32ddc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: List of actors who have played the president of the United States\\nSummary: This is a list of actors who have played the role of a real or fictitious president of the United States.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_tool.invoke(\"attention all you need\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "HprnmKgL67JZ",
        "outputId": "827a1e63-e72f-4d2b-b99b-909a4decbf11"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don\\'t Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time on the performance of\\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\\ndecreases performance but leads to the best speedups alongside dropping entire\\nlayers. For example, removing 33\\\\% of attention layers in a 13B Llama2 model\\nresults in a 1.8\\\\% drop in average performance over the OpenLLM benchmark. We\\nalso observe that skipping layers except the latter layers reduces performances\\nfor more layers skipped, except for skipping the attention layers.\\n\\nPublished: 2023-03-02\\nTitle: Methods used in nanostructure modeling\\nAuthors: I. Camps\\nSummary: How many times you need to change your method description because you were\\n\"accused\" of plagiarism from text you already published? I will use this\\npreprint to add all the methods I currently used in running the simulations for\\nmy research works. Then, I will cite it as needed.\\n\\nPublished: 2021-07-16\\nTitle: All the attention you need: Global-local, spatial-channel attention for image retrieval\\nAuthors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\\nSummary: We address representation learning for large-scale instance-level image\\nretrieval. Apart from backbone, training pipelines and loss functions, popular\\napproaches have focused on different spatial pooling and attention mechanisms,\\nwhich are at the core of learning a powerful global image representation. There\\nare different forms of attention according to the interaction of elements of\\nthe feature tensor (local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses only one or two\\nforms of attention and applies it to different problems like classification,\\ndetection or retrieval.\\n  We present global-local attention module (GLAM), which is attached at the end\\nof a backbone network and incorporates all four forms of attention: local and\\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\\npooling, we learn a powerful embedding for image retrieval. Focusing on global\\ndescriptors, we provide empirical evidence of the interaction of all forms of\\nattention and improve the state of the art on standard benchmarks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [wiki_tool]"
      ],
      "metadata": {
        "id": "GbxFt3zw7Gx8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "CJY6hB3d8fi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langgraph Application\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict) :\n",
        "   messages : Annotated[list , add_messages]"
      ],
      "metadata": {
        "id": "rGcorREW76M8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph , START , END"
      ],
      "metadata": {
        "id": "EDb1koa98J2o"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder =  StateGraph(State)\n",
        "\n"
      ],
      "metadata": {
        "id": "-TrGpX-n9VvC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  langchain_groq import ChatGroq\n"
      ],
      "metadata": {
        "id": "3UBXotNx99IT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq = userdata.get(\"groq_api\")"
      ],
      "metadata": {
        "id": "tiAM28OG-PjC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm =  ChatGroq(groq_api_key = groq , model= \"gemma-7b-it\" )"
      ],
      "metadata": {
        "id": "wAIYzLVq-GS4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"who is the current predent of USA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps9upYJl-Ic2",
        "outputId": "1ea05e88-15f5-4bd2-e852-a9294b5ea1ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='As of today, **Joe Biden** is the current President of the United States.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 17, 'total_tokens': 35, 'completion_time': 0.019137565, 'prompt_time': 0.011061086, 'queue_time': 0.003332304000000001, 'total_time': 0.030198651}, 'model_name': 'gemma-7b-it', 'system_fingerprint': 'fp_7d8efeb0b1', 'finish_reason': 'stop', 'logprobs': None}, id='run-cae82882-864e-46de-9356-bee3ba7f5a09-0', usage_metadata={'input_tokens': 17, 'output_tokens': 18, 'total_tokens': 35})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.bind(tools=tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqamnZspEvPh",
        "outputId": "75cf0da9-fb66-4752-f36e-6bfd936e7a2c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f03d3c27fd0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f03d3c2f730>, model_name='gemma-7b-it', groq_api_key=SecretStr('**********')), kwargs={'tools': [WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=300))]})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State) :\n",
        "  return {\"messages\" : [llm.invoke(state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "ozP5HKdDAWvX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder.add_node(\"chatbot\" , chatbot)\n"
      ],
      "metadata": {
        "id": "BGmVZ4HHD9t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder.add_edge(START , \"chatbot\")\n"
      ],
      "metadata": {
        "id": "o_0_V8HjE1NG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langgraph"
      ],
      "metadata": {
        "id": "nfznQVyaGTDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode,tools_condition"
      ],
      "metadata": {
        "id": "7_DcSw9JFzUI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_node =  ToolNode(tools=tools)\n",
        "graphbuilder.add_node(\"tool_node\" , tool_node)\n"
      ],
      "metadata": {
        "id": "TA3H-5eFGE_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder.add_conditional_edges(\"chatbot\" ,\n",
        "                                   tools_condition)"
      ],
      "metadata": {
        "id": "YsBgkBh6IA9I"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder.add_edge(\"tool_node\" , \"chatbot\")\n",
        "graphbuilder.add_edge(\"chatbot\" , END)"
      ],
      "metadata": {
        "id": "FQX3Wg9OI1H9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphbuilder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LPXS7qMJKxc",
        "outputId": "19127dab-df1b-4ada-969b-189270292c64"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7f03d3d0d6f0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graphbuilder.compile()"
      ],
      "metadata": {
        "id": "68wERKrMJNHE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "66P_KLdDJYhn",
        "outputId": "ae42d854-562f-476f-de37-1ca7605f7f92"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAD5ANsDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAUGBAcCAwgBCf/EAFEQAAEDBAADAwYHCQ0GBwAAAAEAAgMEBQYRBxIhEzFBCBQVIlFWFhcycXWU0yMkNkJhlbTR0jQ1N1NUVWJygZGhsrMYM1J0k8ElQ0RForHh/8QAGwEBAQADAQEBAAAAAAAAAAAAAAECAwQFBgf/xAA1EQEAAQICBQkHBAMAAAAAAAAAAQIRAzEEEhRRkSEzQVJhcaHB0QUiYoGSsfATI0PxMkKy/9oADAMBAAIRAxEAPwD9U0REBERAREQEREBFi3O5U9nt89ZVPLIIW8zuVpc4+xrWjq5xOgGjZJIA2SoIWCrycdvfZJaeldsx2eCXkY1p7u3e07kf7QDyDegH65ztpoiY1qptH5ktkzVX220UhZUXClgeOhbLO1p/uJXT8KrL/PFB9ZZ+tdVPheP0jAyCxW2JoAGmUkY7ug8F2/BWy/zPQfVmfqWf7Pb4HIfCqy/zxQfWWfrXKPJrPK4NZdaF7j3BtSwn/wC1x+Ctl/meg+rM/UuMmJWOVhY+y297D3tdSxkH/BP2e3wXkSrXB7Q5pBaRsEeK+qsvwemtz3VGPymw1Wy7s4G7pZCf4yDYaRvxbyu9jhtSVjvTro2eCpg8zuVK4MqaYu5g0kbD2O0OeN3e12h3EENc1zRjVRFtaibx4pbclERFpQREQEREBERAREQEREBERAREQEREBERBV7vq7ZtZ7a/TqajgkuUjD+NIHNjh+cDmld18WsPeNi0KsTjzPiRSyO2GV1sfC12unPFIHcu/aRK4j+qfYrOujFyoiMrec38Vlqm2+VFwzvtRkFNaclbdKix0dRXVjaWjqHsEMGhK5jxHyy8pIH3MuOyNb2q3wW8r7EeKHCetzK5yPsD7XEJ7vSebVMrKJr5nsiDZOyAmJDBvswdE9QFrrgTbMlxri+/G8Lx7M7Bwrmp659xteYW8Q01tqXEmM0ExJc9j3kksBIAcSdn5NUwm7cUcR8k6l4f2TDMzx/KsaqmQXWtpraOeajfWSOldbpHEiaXkcOrR02SD3Fc6PTVq8prhne8DvmZUWUxT49Y3NbcpxSziWlLiA3ngMfajZPT1OvX2FUTiX5buDYpgD8kxuofkwFxp7cPvOrghJkO3PbIYdPDWBzvV79AA7IXnK4cPcqq8Y8ocW7E+IVTS5LZLTJan5TTTVNyr3QzckgeQHHnBJIjPrBgB0AvSflQ4Peb55NNFQY7ZKi5V1pmtdYLTRR/dnxwSRl7I2eLg0H1R16aHXog3VhmZWniBjNFkFiqJKq1VocYJpaeWnc4NcWHccjWvb1ae8D29ywsl1askx+6x6aZpzban+nHI1zmfORK1mt9we/XeQcjA8v8Ah3i1HexZbxj4qS/Vvv1IaWsi5Xubt8RJ5d8vMOvUEHxXRmg87q8coG7Mk9zjmOhvTIWulLj7BtjR87h7V0YH+dui08LLGazoiLnQREQEREBERAREQEREBERAREQEREBERBFZFZTeaKPsZGwV9LKKmjqHAkRTAEAkAglpDnNcARtr3DY3tcbNkUNzlfSTs8yusI+7UMh9Yf02Egc8Z8Hga8DpwLRLqOvOP27IIY47hSR1HZkuiediSJxGuZjxpzDrptpBW6mqmY1a8vt+fnTe96RRVc4MY+lPkV9pmdwZ54JdD55Gucf7TtPgTUe9V+/60P2Sy1MPr+Elo3rQi1Xwrt91zLArXeLhlN5FZU9rziCSEM9WV7BodmfBo8VbPgRMQQ/J789p7x5xG3/FsYP+Kfp4fX8JLRvTd2vFHY6XzitnbBHvlaNFzpHeDWNGy9x8GtBJ8Ao2yW+orbnJfLjD2FS+LsKSmJ26mgJDnB3h2j3NaXa6DkY0b5eZ3basPtdoq/PI4X1Nfojz2tmfUTgHvDXvJLQenqt0Og6dAppSaqaIth9PT+fnm7hERaEEREBERAREQEREBERAREQEREBERAREQEREBERBr3gAQeElh0dj747/APmJPylbCWveAG/iksW9b++Pk61+6JPZ0WwkBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERBrzyfhrhFYeod+6Oo7v3RIthrXnk/a+KKw66j748Nf+okWw0BERAREQEREBERAREQEREBERAREQEREBERARYd3utPZLdPW1Ti2CIAnlaXOcSdBrQOpJJAAHeSFV35Flc+nw2m1U8buoiqa2R0jRr8blj5d+0Akewlb8PBrxIvGXbyLZdEVI9O5h/ILH9bm+zT07mH8gsf1ub7Nbdlr3xxgsu61h5RvGSs4C8M6jMaXGZMpgpKiOOrpo6sUxhhftva83I/YD+Rutfj730Ux6dzD+QWP63N9mo3Jochy/HblY7raLFVW2408lLUQuq5vWje0tcP930Oj3+CbLXvjjBZpXyFPKUquNFrrMchw6S1WywU7pJbu6uErXzSzOcyIRiJuiWmQ73+J3denrNee/J64Q3XydsAGMWams9bz1MlVU109RK2Sd7jobAjOg1oa0D8m/ErZvp3MP5BY/rc32abLXvjjBZd0VI9O5h/ILH9bm+zT07mH8gsf1ub7NNlr3xxgsu6Kki+5eD1t9kI9grJhv8At7Lop7HshF6FRDNAaO4Urg2emLucDe+VzXaHMxwB0dDuIIBBA114FdEa02t2TcsmERFzoIiICIiAiIgIiICIiAiIgIiIKnxNOsdpPYbrbtg/85EslYvE38HaT6Wt36XEspenh8xT3z5L0CIofLsutOCY7WX2+VfmNqow0z1HZvk5A5waPVYC49XAdB4qImERFQRVqv4k4zbsXpcjkvEEtjqqiGlgrqbmnjlkllEMYaYw7YMjg3fcO8kDqrKoCL45wY0ucQ1oGySdABYdmvVBkVrprna6yG4W+qYJIKqmeHxysPc5rh0IPtCozVG46dcRr0PbaqLf5fu1V/8Av95UkozHf4R7z9E0f+tUrL+Ovu84WOldkRF5SCIiAiIgIiICIiAiIgIiICIiCpcTfwdpPpa3fpcSyli8TfwdpPpa3fpcSyl6eHzFPfPkvQ1v5Rua3Th5wWya/WWVlNc6eOKKGpkYHtpzLNHEZiD0PZiQv69PV69FrDj5wxbhHk85vNFlmTX2Wpo6aN7r1dHVjOfzmI9qxjhphPsbpuvBejbraqO+Wyqt1xpYa6gqonQz007A+OVjhpzXNPQgg60td0Hk18ObbaLjbILBJ5jcIGUs8Mtyq5PuLZGyNjYXSkxtDmtPKwtHT2LCYmUa+ul4dwS4i5LbrjluS3LF5MJqr9VSV9Yauqp54Z2RGSnc4aYXNl6MADA5rdABRnCU5bb+LgxW9z5BRWDI8Vqa9lJdcmfcq2GRk0LBK2UMa6mfyzOBbG9wBAIILVv+9cO8cyK9T3W52uKurZ7XNZZXTOc5klHK9r5InR75SHOY3qRvpretqDxTgNg2E3uhvFnsz6e60Ub4IK2WuqJ5RE9oBiLpJHF0YAGmO21p6tAPVTVm48xWDEKej8ifFpoLldhLdrrZ2yGW4yzNpiLqxu6dkjnNhI2SQwAEgEg6Vp4l5dk/k/3jO7Rj+SXW/wBGcOffqf09UmumtdSKplPztkftxjLZHP5HbG4TrpsLdX+zlw78wu1B8HR6Ouk7KmqofPKjzd0jZe2BZF2nJGO09YhgaD4gqUxTgxhmF0d4prXY4xHeGdlcX1s0lZJVx8pb2ckkznuczTnDlJ0Nnp1U1ZGprlYa3AOIuL4pT5lkmQ2vL7JdI7i243WSaWN8MMb2VcEgIdASXubqMhvrN0AQCrF5HWN01l8n/DquCsuFS+42ynmkZWV8tRHE4N1yxMe4tib/AEWAD8iumC8FML4bXKW4Y9ZRSV0kApfOJqqapfHCDsRRmV7uzj3o8jNN6Dp0CzME4V4vwzdcDjVtda4694fNAypmfC0hznajje8siG3uPKwNHXuViJibi2KMx3+Ee8/RNH/rVKk1GY7/AAj3n6Jo/wDWqVu/jr7vOFjpXZEReUgiIgIiICIiAiIgIiICIiAiIgqXE38HaT6Wt36XEspZ+S2QZDZ5qMTGmlLmSwzAc3ZyseHscRsbAc0bGxsbGxta9sPECqyOor6e2WCovRt8vm9RWWuphkozKNhzI5pHsEhaQ4ODdlhGnBp6L0sGYqwoovF4mc5iM7b+5lnC5ooT0tfvcy6/WqL7dPS1+9zLr9aovt1t1Pij6o9SybRQnpa/e5l1+tUX26xG5Xdn3eS2DDbz53HA2pd90peQMc5zR6/bcu9td6u99N60Qmp8UfVHqWWZFWbnld2tEcElTht5DJp46dpikpZPXe4NbvlmOhsjbjoDxICy/S1+9zLr9aovt01Pij6o9SybRQnpa/e5l1+tUX26elr97mXX61RfbpqfFH1R6lk2ozHf4R7z9E0f+tUqo8R+Lh4UYlWZLkuLXmhs1IWiepj7CcR8x5WlzYpXOAJIG9aGwqh5P/lZ8NuLeaSW+23if4VXZpjp7bJRzNa2GBskgHOW8vNoyPJPKOoaNloLsa7UYdUTMcsdExPTG4yek0RF5TEREQEREBERAREQEREBERAUTk+VWzD7Wa+6TmGEvEUccUbpZp5D8mOKNgL5HnR01oJPsUdleZPs9XBaLRRemclqozJBQdoY44mb121RIA7sogQRvRc4ghjXEELpxjAm225enb3VNv2VPjMTri+Ls46djjt0VLES7sYyQNgEufyt53vLQQEUywX7iO4y5M2SwY44EMxyCUecVTSNffkzCQAf4iI8v/G+QOLBfKKip7bRwUlJBFS0sDGxRQQsDGRsaNNa1o6AAAAALuRAREQFAY/Iay+ZDVc11YxtQykbBXsDIPucbSZKca2WOMhBce9zDroBuXuFYLfQVNUYZqgQROl7GnZzyP5QTytb4uOtAeJUdh1BJbsbo45pbjLNKHVMnpWYS1DHSuMjo3OHT1C8tAb0aGgDoAg45ox7sVub45LlE+CE1A9DgGreY/X5IgejnO5eXlPQ82vFS1NO2qpopmte1sjA8NkaWuAI3og9QfyFdqruCNdS4+y2u9MSG2SvoPOb4Q+pqRGdNmMg/wB4HDRD+879b1toLEiIgjMmxu35hjtysd2p21dtuNO+lqIXfjMe0g/MevQ+B6rzR5O3kXVvk3R3q82HJKa4ZXVzyxMbW0gNHJQCTcUDnAdrG9wa1znscWtcQCyURjm9VIgq2L5/TX24S2iupJ7DkUDeeW1V2ud7AddrC8Etmi7vXYTrYDwx22i0qGynELTmdvZSXWl7ZsUgmgmje6KemlAIEkMrCHxvGzpzSD1I3olVl2RXfhuS3KagXPGW7Lcl0GSUjep+/WNAa1gAH3wzTe8vbGG87gv6Lix7ZWNexwexw2HNOwR7QuSAiIgIiICIiAiIgKsZtlFXZm0Nss8DKvIrq90VFFK0mKFrQDJUTaIPZRggkAguc5jAQXgqzrXuCH09xFz2+T6e6iq4bDRbA+5wRQRzSEewumqJAfaIo99w0FmxTE6XFKOdscklZX1cpqK641JBnq5iAC95HsADWtGmsa1rWgNaAJxEQEREBEUbeLzHa+wgbqSvqy6OkgLXkSPDSfWLGuLGdOryNDY8SAQwMkpXX2uoLM6lqJKB7hWVVXBViEQ9lIx8UbgDzvEjgQWgcpayQOOiGvsKisfsjbRTyTTMpXXas5JrjV0sJibUziNrC8Nc57g3TAGtLncrQBs6UqgKvvpprXmLamGmrammusQiqZBUB0FJJECY3dkeo7QOc1zm+McYI67FgWDerLQ5Fa6i3XGnbVUVQ3lkidseOwQR1a4EAhwIIIBBBAKDORQtsu00FaLXdZaf0m8SSw+bxyNjmhDtAgu2OcDXM0OcR0d0DgppAREQEREGv6RzuGmVW+ztIGJXqR0FvYSB6NrdPkMAP8TK1rjG3/y3MLAeWSJkewFr7j640vCHJLmyTsZrPA28xSbI5H0j21DT0663F19o2PFbBQEREBERAREQEREBa94bvFBm/Eq0uPrNu8NxiB/ip6OAb7/42KceHd862EtHZjxjwbhbx0rpb/l1mtLarGyK6GeriEsMlJKJImOYDz87462RzGaJeGHlB8Q3iiwbHeqPJLLb7tbpTPb6+njqqeUscwvie0OY7lcA4bBB0QCPELOQEWFer3bsbtdTc7tX0trttM3nnrK2ZsMMTe7bnuIDR17yVjXm9OpXOoaBsNXenwmaCjkk5AWh7WF73aOmgvBPQkgHlBI0g5Xm+xWySKjiMdReKqKZ9FQOkLDOY27OyAeRgJY0vI0C9g73NB52m1OopamrqJXTV1X2bp/XcYmFrA3liafks2HO17XuPiuy2WsW0VJdVVFZJPPJO6SpeHFvMejGgABrGtDWgAD5O3czi5xzUBERARF8J0EGJd7XHebbPRyyTQtlA1LTyFkkbgdtc1w7iCAR8ywqa9yU1yFvu3m9LUVNRK23mNziKmNrWv8AEabIAXepskiN7x0BDcObiZiNO8skye0NcNjRrY/A6Pj7QR/YqRxl4pUz+FmTx4TfLNX5XNQyQW6M3iGlLJXjk7USOOgYw4vAOuYsDdt3sdGz43UnhK2nc2pTXClrZquGnqYZ5qSUQ1EcUgc6GQsbIGPA+S7kex2j109p7iFkL81/IQy3K+FHGrJ7ZnrqhlBk0bp6m71VS2aJ1bGS8SPnDiDztdINk9XFvivf/wAaWHe9No+ux/rTZ8bqTwldWdy0oqt8aWHe9No+ux/rT40sO96bR9dj/Wmz43UnhJqzuQ/lAgy8F8vpGs7R9woXW5rOvrOqCIAOnXvkC2CtPcU+IeM3v4JWqnv1sqaapyCkmrJGVMbmQRU3NVh7z1DQZKeJgJ/Ge0DqVePjSw73ptH12P8AWmz43UnhJqzuWlFVvjSw73ptH12P9afGlh3vTaPrsf602fG6k8JNWdy0oqt8aWHe9No+ux/rX1vFHDnOAGU2fZ9tdGP+6bPjdSeEpqzuWhFxjkZNGySN7XxvAc1zTsEHuIK5LnQRFqrijxHqKaslsFlmME8YHntcz5UWwCIo/Y8ggl34oI16zts6tG0bE0rEjDw/6F6vma2HGpBFc7vR0UxHMIZJR2hHtDPla/Lpfnp5W/k5YvnnFqzZfhVxj82vVwjZkNK2F47EueOerbtvUEElw799euzrfkNNHAXFjfXeS573Eue8k7Jc49Sd+JXYvqqPYeBEe/XMz2WjykvDddJxcwehpYaanu0cUELGxxxtp5dNaBoAer4ALNpuLeH1T2tF/pIie41BMI/veAFodCA4EEbB6EFZz7D0foqq8PQvDh5f9Dm+d8LrJheBWC4X52Q1gkraigjL4YqeLle0SP8AktD3uYRsjfZnXcpzyLcD4u8NcC9AcSzbZqGljbHaiKszV9LE3up5HNaWPiHMeT19s6t6tLQzpxLJq3BavtraC+ic4untnPyxSb7y0dzH+Oxrf42+8ehrLeKTILVTXGhlE1LUMD2OH+II8CDsEeBBC+c07QK9Cqi83pnKTuZqIi8sEREBVHiI/t47FbJDukudx83qY9dJY2wTTFjv6LjE0EdxBLSCCQrcqdxA/fXDPph/6BVrq0bnY+fhErGbNYxsbQ1jQ1oGgANAL6iLpQREQEREBERAREQF8IDgQRsHoQV9RBg4K4Ud3yC1Q+pRU0kM0MI+TF2jCXNb7BzNJ0Og5jpXFUvDvwxyn+rSf5Hq6Ln0rnflH2hlOboraptDRz1L/kQxukd8wG/+y8sW+eWspW1c7uepqyamZ+tcz3nmcf7yvVFbStrqOemf8iaN0bvmI0V5XoKeWipm0dQ3kqaQmmmZvfK9h5Xf4hfRewdW2Jv5PNjOSo8U+KNJwyttBI+kdcrlcqkUlDQtmZCJZCNkukf6rGAd7j3bCo8vlNQ0OI5Xca7H/N7zjnmz6m2Q3GOeOWKaRrGvjnYC12uYkjXeAOm+lk428KJ+JlFZKigdbjdbNV+cwQXin7ejqGkafFKzR9U6HUAka/tFUvPA2837hHlNg9E4XYcguz4RFJYaR1NTCKOWN/LI/k53H1Hker+MPnXr41WlRXV+nlabcPvf+mK1WHjFVOyqosWVY5JilS22vu0Ej6xlUySnYdP5iwDle3vLevcevdvWeW8W8gzur4b1tNjdbYMXrsrovNbnJXs562PmeOR8DfWa13Vw2SDy/MtoZZwvqcq4l0d6mmgbZhYqq0VMXO4TkzHvaOXl1rfUn+xUK38F+IrKXB7HX3THKvHsVvNNXQTxieOsmhiLgGuHKWBwa4gAd/TbunXVixpE+5yzF8+Tlyz7M8h6EWz+A1zeY7/aSSY6aaOrjB7mNmDgWj8nPE93zvK1gtn8BbY8RX+7kER1U8dJET3PbCHbcPyc8j2/Owq+1tXY69bst339LsqeltdERfn4IiICp3ED99cM+mH/AKBVq4qncQP31wz6Yf8AoFWurRec+U/aVhnLVHlPZlkuBcIK+74qIm3NlZRwumkmEZijkqY2OLdxvDi7mDO4aDy4HbQDtdUjjXgFVxP4ZXrG6Grioa+qEMtNUTtLo2yxTMmZzgdeUujAOuuiVvnLkRAXzi7klquVgxmmw2muWeXKknuFRaoLxy0dFSxyBnavqnQgnmLmAARb2SOgGzFx+UkbnaLHT2jFqisza6XOstHwcqKtkIpaik2aoy1GnNEbBykOa1xd2jNN2dD7csF4kTZRY88o24tFmNPb6iz19skqak0FRSvlZLG5k3Zdo17Xs31jIIcR071CW/yfMpxmGw5Na7taa3iBR3m5XmtbWNlit1Ua9obPA0tDpI2tDIeR2nH7n1b62hj7w6co4xXPJ34hRmmrMSyC25/Q2a92uGt52uY+CSUN7RnKJYZGOY4bA3rq3ovRS8713k/5hXW2tyKS6WV/EKqymkyd0REwtoFND2EVLz67TlEW9ycuy4/JWyavjhjNDVTU00GRmaF7o39lit0kZzA6PK5tMQ4bHQgkHwVibZiq5dx+vljvnECkteD+maDCWxT3KsddmQGSF9KyoJhjMbi6RrXP9QloIaCH7dyjMunHS43W/utOB4i7MZ6a1012rpJriyhjgiqGudBG0uY/nle1rncumtA1tw2seDhrcshg4w3OkqKdtNn1DC21ipZNBLD/AOHCn++I3xh0fr9daJA7wD0UXbOEef8ADu4NueF1eOT1lxsNutV1gvL52xxVNJE6OOohdGwl7eV5BY4N3ytPMO4TlEm3yjW5PS4jFgmNzZReshtzruKGpq20LKGla4RvdPIWv04SExhrWu25ruoA2td4V5Sc2DYDEchMVRlF5ya9w01Hfr7FSwUkcFU/nZJVy7a1kYcyNoaHb2A1ut6s9i8n3KOFE+G3LBLnablcrXZH2K6Q3/tYYa2N05qDNG6Jr3RvEzpDykOBa/WxrajrP5O+bY/BY8hpK/HZc0td4vFY+lqO2NtrKWvm7R8TncvaRuaQxzSGu0QQeYdVPeGz+C3Ga38Y7VdpqaGnp6601nmVZFR18ddTlxY17XxVEfqyMLXDroEEOBAIWxVX8Hpr/T2MfCWKzwXZ8jnPjsYk83Yzfqt5ngOcQO92hv2BWBbIy5RHYd+GOU/1aT/I9XRUvDvwxyn+rSf5Hq6LRpXO/Kn/AJhlVmLVnFHhvU1lZJfrJD29Q8Dz2ib0dNoACWP2vAABaflADWi3T9popo2k4mi4kYmHn92LyrFUxzOexriJGHT4ngtew9xDmnq0/kIXYvRt8w2xZK8Puloo66UDQlmhaXgewO7x/eoQ8G8NP/scX9ksn7S+qo9uYMx79ExPZafQtDRqOcGtJcQAOpJ8FvL4m8N/mOL/AKsn7S76XhNh9I9r249RSlvUecR9sB49z9rKfbmj9FNXh6loaaxHF67OqoR27mioASJrnybij13hhPR7/DQ2B+N4A+hbPaKWw2umt9DEIaWnYGRsHs9pPiSepPiSSsuONkMbWMaGMaA1rWjQAHcAFyXzunafXptUXi1MZQvcIiLy0EREBU7iB++uGfTD/wBAq1cVUeIjBBFY7pICKS2XDzmpk30ijdBNCXu6fJaZQSe4AFxIAK6tG52Pn4xKxmy0XGORkzGvY5r2OGw5p2CuS6UEREBERAREQEREBEXxzgxpc4hrQNkk9Agj8O/DHKf6tJ/keroqdgjRWXa/3aH16KqkhiglHyZRGwhzm+1vM4jY6HlOlcVz6Vzvyj7QynMREXIxEREBERAREQEREBERAREQVqfhpiNVIZJsXs8jz3udQRE9+/8Ah9pK6/irwz3Tsn5vi/ZVpRdG0Y0f7zxlbzvVb4q8M907J+b4v2U+KvDPdOyfm+L9lWlE2jG688ZLzvVb4q8M907J+b4v2U+KvDPdOyfm+L9lWlE2jG688ZLzvVb4q8M907J+b4v2U+KvDPdOyfm+L9lWlE2jG688ZLzvVb4q8M907J+b4v2U+KvDPdOyfm+L9lWlE2jG688ZLzvVb4q8M907J+b4v2VyZwuw6N4c3FLKHDqD6Pi6f/FWdE2jG688ZLzvcY42xMaxjQxjQA1rRoAewLkiLnR//9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Hi there  , my name is fahim\""
      ],
      "metadata": {
        "id": "XSffwZZiJci7"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = graph.stream(\n",
        "\n",
        "        {'messages' : [(\"user\" , user_input)]} , stream_mode = \"values\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "yIqBzyvxJlId"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in events  :\n",
        "  event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "r6mSgHinJ2ky"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in events  :\n",
        "  event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "hIZXEWqRKBDj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input=\"tell me about llm model \"\n",
        "\n",
        "events=graph.stream(\n",
        "     {\"messages\": [(\"user\", user_input)]},stream_mode=\"values\"\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "  event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJYUaWSvKMMH",
        "outputId": "1a31c17c-9890-4516-b299-4fcfc3cec48a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "tell me about llm model \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "**LLM (Large Language Model)**\n",
            "\n",
            "LLM (Large Language Model) is a type of statistical language model that can generate human-quality text, translate languages, summarize documents, and answer open-ended questions. These models are trained on massive datasets of text and code, allowing them to learn the patterns and relationships between words and concepts.\n",
            "\n",
            "**Architecture:**\n",
            "\n",
            "LLM models are based on Transformer neural networks, which rely on attention mechanisms to capture the relationships between words in a sentence. The model learns to predict the next word in a sequence given the preceding words.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "- **Generative:** LLMs can generate new text, stories, and code.\n",
            "- **Translational:** They can translate languages with high accuracy.\n",
            "- **Summarizing:** LLMs can summarize long documents into concise summaries.\n",
            "- **Question-answering:** They can answer open-ended questions based on the text they have been trained on.\n",
            "- **Contextual understanding:** LLMs can understand the context and intent of a conversation.\n",
            "\n",
            "**Popular LLM Models:**\n",
            "\n",
            "- **GPT-3:** A large language model developed by Google.\n",
            "- **DALL-E:** A model that can generate images from textual descriptions.\n",
            "- **ChatGPT:** A conversational AI that can engage in human-like conversations.\n",
            "- **Code-LLM:** A model that can generate and understand code.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "LLMs have numerous applications in various industries, including:\n",
            "\n",
            "- **Content creation:** Writing stories, articles, and marketing materials.\n",
            "- **Customer service automation:** Providing automated responses to customer inquiries.\n",
            "- **Translation:** Translating documents and conversations in real-time.\n",
            "- **Summarization:** Summarizing news articles and research papers.\n",
            "- **Code generation:** Generating code from natural language descriptions.\n",
            "\n",
            "**Limitations:**\n",
            "\n",
            "- **Bias:** LLMs can inherit biases from the training data.\n",
            "- **Lack of common sense:** They may generate nonsensical or illogical output.\n",
            "- **Ethical concerns:** The use of LLMs raises ethical considerations related to privacy and bias.\n",
            "\n",
            "**Future Directions:**\n",
            "\n",
            "LLMs are constantly evolving and improving. Future models are expected to be more accurate, creative, and impactful. LLMs have the potential to revolutionize various industries and enhance human capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-dOYFvI1KYUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}